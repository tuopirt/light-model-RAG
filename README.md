# ðŸ§  Lightweight Local RAG (Retrieval-Augmented Generation)

This project is a minimal, local **Retrieval-Augmented Generation (RAG)** pipeline â€” designed to answer questions grounded in PDF documents using a fully offline setup for Bluestaq

It uses a quantized **Mistral 7B** model, **SentenceTransformer embeddings**, and **ChromaDB** for vector storage.

---
files - use to store exsisting text corpus.
tests - any test files.
model - where you would download and put the desired LLM model.
main.py - our program file.
requirement.txt - required libraies to run our program, generated by ChatGPT.
README - overview of this repository.

---

all code done by me, half writings written with GPT

